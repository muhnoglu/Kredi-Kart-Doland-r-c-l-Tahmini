{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6492730,"sourceType":"datasetVersion","datasetId":3752264},{"sourceId":10090034,"sourceType":"datasetVersion","datasetId":6221682}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ![CreditCardImage](./image-112.png)","metadata":{}},{"cell_type":"markdown","source":" # Veri Ön İşleme ve Standartlaştırma\n\n\n**İşlem tutarları gibi sürekli özelliklerin standartlaştırılması (StandardScaler kullanımı).Log dönüşümü gibi yöntemlerle veri dağılımının düzenlenmesi.\nÖzellik Mühendisliği:Yeni özellikler türetilmesi (etkileşim özellikleri, kare alma gibi doğrusal olmayan dönüşümler).Özellikler arasındaki yüksek korelasyonların analizi ve gruplanması.Modelleme:Veri kümesinin eğitim ve test setlerine ayrılması.RandomForestClassifier gibi bir modelin kullanılması.\nÇapraz doğrulama ve model değerlendirme metrikleri (accuracy, classification_report).Özellik Önemi:Özellik önemlerini analiz eden bir grafik ile önemli değişkenlerin belirlenmesi (plot_importance_ensemble fonksiyonu).**\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\npd.set_option(\"display.max_columns\",None)\nimport shutil\n# data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T22:57:46.593577Z","iopub.execute_input":"2024-12-03T22:57:46.594080Z","iopub.status.idle":"2024-12-03T22:57:50.287446Z","shell.execute_reply.started":"2024-12-03T22:57:46.594033Z","shell.execute_reply":"2024-12-03T22:57:50.286191Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/credit-card-fraud-detection-dataset-2023/creditcard_2023.csv\n/kaggle/input/creditcardimage/image-112.png\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"shutil.copy('/kaggle/input/creditcardimage/image-112.png', '/kaggle/working/image-112.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LOAD DATASET\n\n**Veri Setini Yükleme Ve İlk Beş Satır**","metadata":{}},{"cell_type":"code","source":"# Veri setini yükleme\ndf = pd.read_csv(\"/kaggle/input/credit-card-fraud-detection-dataset-2023/creditcard_2023.csv\")\n\n# Veri setinin ilk 5 satırını görüntüleme\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis\n**Keşifsel Veri Analizi**","metadata":{}},{"cell_type":"code","source":"# Veri setinin boyutları\nprint(df.shape)\n\n# Eksik değer kontrolü\nprint(df.isnull().sum())\n\n# Sınıf dağılımı\nprint(df['Class'].value_counts(normalize=True))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Visualization\n\n**Veri Görselleştirme**\nSınıf Ve Tutar değişkenlerimizi görselleştiriyoruz.\nİki değişkeninde hemen hemen normal dağıldığını söylemek mümkün ve iki değişkenimiz için de ayrkırı değerimiz olmadığı ortada.","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=\"Class\", data=df)\nplt.title(\"Sınıf Dağılımı (Fraud vs Not Fraud)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.histplot(df['Amount'])\nplt.title(\"İşlem Tutarı Dağılımı\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.boxplot(x=df['Amount'])\nplt.title(\"İşlem Tutarı Dağılımı (Boxplot)\")\nplt.xlabel(\"İşlem Tutarı\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.violinplot(x=df['Amount'])\nplt.title(\"İşlem Tutarı Dağılımı (Violin Plot)\")\nplt.xlabel(\"İşlem Tutarı\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.violinplot(x='Class', y='Amount', data=df, scale='width')\nplt.title(\"Sınıf ve İşlem Tutarı Dağılımı (Violin Plot)\")\nplt.xlabel(\"Class (0: Fraud Değil, 1: Fraud)\")\nplt.ylabel(\"İşlem Tutarı\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Class'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.groupby('Class')['Amount'].mean()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**İşlem tutarlarına göre doladırıcılık  durumuna  bakıtığımızda dolandırma tutarları normal işlem tutarlarına göre dafa fazla miktarda olduğu görünüyor bu miktar az da  olsa önemli bir fark yaratıyor.**","metadata":{}},{"cell_type":"code","source":"sns.stripplot(x='Class', y='Amount', data=df, jitter=True, size=2, alpha=0.7)\nplt.title(\"Sınıf ve İşlem Tutarı Dağılımı (Strip Plot)\")\nplt.xlabel(\"Class (0: Fraud Değil, 1: Fraud)\")\nplt.ylabel(\"İşlem Tutarı\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"Class\", height=5, aspect=1.2, palette=\"viridis\")\ng.map(sns.histplot, \"Amount\", bins=50, kde=True)\ng.set_titles(\"Class {col_name}\")\ng.fig.suptitle(\"Sınıflara Göre İşlem Tutarı Dağılımı\", y=1.02)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Veriyi ön işlerken tekrar aykırı değerler ve null değerlerin olup olmadığını gözden geçiriyoruz ","metadata":{}},{"cell_type":"code","source":"# Null değerlerin toplamı\nprint(df.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tutar Değişkeninin z-score ve Iqr yönetmiyle aykırı değer tespiti","metadata":{}},{"cell_type":"code","source":"# Belirli bir sütun için IQR hesaplama \nQ1 = df['Amount'].quantile(0.25)\nQ3 = df['Amount'].quantile(0.75)\nIQR = Q3 - Q1\n\n# Aykırı değer sınırları\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Aykırı değerlerin tespiti\noutliers = df[(df['Amount'] < lower_bound) | (df['Amount'] > upper_bound)]\nprint(f\"Aykırı değer sayısı: {len(outliers)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tutar sütunu için Z-Score\ndf['z_score'] = zscore(df['Amount'])\n\n# Z-Score > 3 veya < -3 olanlar\noutliers_z = df[(df['z_score'] > 3) | (df['z_score'] < -3)]\nprint(f\"Z-Score yöntemiyle tespit edilen aykırı değer sayısı: {len(outliers_z)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**sınıf değişkeni herhangi bir aykırı değer olmamasıyla beraber  normal bir dağılım seyretmiş diyebiliriz**","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='Class', y='Amount', data=df)\nplt.title(\"Classlara göre İşlem Tutarlarının Box Plot Grafiği\")\nplt.xlabel(\"Class (0: Fraud Değil, 1: Fraud)\")\nplt.ylabel(\"İşlem Tutarı\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Veri Setimizi Güvene Alıyoruz","metadata":{}},{"cell_type":"code","source":"df= df.drop('z_score',axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1 = df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering(Özellik Mühendisliği)\n**Feature engineering (özellik mühendisliği), makine öğrenimi modellerinin performansını artırmak ve daha iyi tahminler yapmasını sağlamak için veri setindeki özellikleri dönüştürme, yeni özellikler oluşturma veya mevcutları yeniden düzenleme işlemidir.**\n\nModel Performansını Artırmak: Daha anlamlı ve iyi tasarlanmış özellikler, modelin doğruluğunu artırır.\nVeri Setindeki Eksiklikleri Gidermek: Eksik veya hatalı verileri temizlemek ve dönüştürmek gerekir.\nAykırı Değerlerin Etkisini Azaltmak: Aykırı değerleri işlemek modeli daha kararlı hale getirir.\nKarmaşık İlişkileri Ortaya Çıkarmak: Özellikler arasındaki ilişkileri keşfetmek ve model için daha anlamlı hale getirmek.\nÖzelliklerin Ölçeklendirilmesi: Modelin hızlı ve etkili öğrenmesini sağlamak için veriler aynı ölçeklerde olmalıdır.\n","metadata":{}},{"cell_type":"markdown","source":"**Modelde Kullanılmayacak Değişkenlerin Kaldırılması**","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**id sütunun modelimizde herehangi bir analam ifade etmeyeceğinden kaldırdık**","metadata":{}},{"cell_type":"code","source":"df = df.drop(columns=['id'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**İşlem Tutarını Standartlaştırılması**","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\ndf['Amount'] = scaler.fit_transform(df[['Amount']])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Daha güçlü  model için güçlü bir bir özellik türetmek için mevcut sütunları analiz edip, yeni bir özellik oluşturuyoruz.**","metadata":{}},{"cell_type":"markdown","source":"**Etkileşim Özelliği Türetme**","metadata":{}},{"cell_type":"code","source":"df['V1_Amount_Interaction'] = df['V1'] * df['Amount']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Doğrusal Olmayan Özellikler Ekleme**","metadata":{}},{"cell_type":"code","source":"df['V1_Squared'] = df['V1'] ** 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Log Transformation ile Yeni Özellik**","metadata":{}},{"cell_type":"code","source":"df['Log_Amount'] = np.log1p(df['Amount'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Standartlaştırılmış Özellik**","metadata":{}},{"cell_type":"code","source":"\ndf['V1_Amount_Interaction_Scaled'] = scaler.fit_transform(df[['V1_Amount_Interaction']])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Korelasyon Analizi**","metadata":{}},{"cell_type":"code","source":"correlation = df[['Class', 'V1_Amount_Interaction', 'Log_Amount']].corr()\nsns.heatmap(correlation, annot=True, cmap=\"coolwarm\")\nplt.title(\"Yeni Özelliklerin Korelasyonu\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Özellik Kombinasyonları**","metadata":{}},{"cell_type":"code","source":"df['V1_V2_Interaction'] = df['V1'] * df['V2']\ndf['V3_V4_Interaction'] = df['V3'] * df['V4']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" **İstatistiksel Özellikler Türetme**","metadata":{}},{"cell_type":"code","source":"df['Mean_V1_V2'] = df[['V1', 'V2']].mean(axis=1) #ortlama ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Std_V1_V2'] = df[['V1', 'V2']].std(axis=1) #standart sapma","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Var_V1_V2'] = df[['V1', 'V2']].var(axis=1) #varyans","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Anonimleştirilmiş Özelliklerin Korelasyonu**","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Korelasyon matrisini hesaplayalım\ncorrelation = df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n                  'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n                  'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']].corr()\n\n# Korelasyon matrisini ısı haritası olarak görselleştirelim\nplt.figure(figsize=(12, 10))  # Grafik boyutunu ayarlayalım\nsns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt='.2f', linewidths=0.5)\n\n# Başlık ve etiketler\nplt.title(\"Anonimleştirilmiş Özelliklerin Korelasyonu\")\nplt.tight_layout()\n\n# Görselleştirmeyi gösterelim\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncorrelation = df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n                  'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n                  'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']].corr()\n\n# Korelasyon değerinin mutlak değeri 0.80'den büyük olanları bulalım\nhigh_corr = correlation[correlation.abs() > 0.80]\n\n# 1.0 korelasyonunu çıkaralım çünkü bu, değişkenlerin kendileriyle olan korelasyonudur\nhigh_corr = high_corr[high_corr < 1.0]\n\n# Korelasyonu 0.80'den büyük olan değişken çiftlerini göstermek\nhigh_corr_pairs = high_corr.stack().reset_index()\nhigh_corr_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n\n# Yüksek korelasyonlu değişken çiftlerini yazdıralım\nprint(\"Yüksek Korelasyonlu Değişken Çiftleri:\")\nprint(high_corr_pairs)\n\n# Maskelenmiş korelasyon matrisini görselleştirelim\nplt.figure(figsize=(12, 10))  # Grafik boyutunu ayarlayalım\nsns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt='.2f', linewidths=0.5, mask=~(high_corr.abs() > 0.80))\n\n# Başlık ve etiketler\nplt.title(\"Korelasyonu 0.80'den Yüksek Olan Özellikler\")\nplt.tight_layout()\n\n# Görselleştirmeyi gösterelim\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**V16,V17  VE V17,V18 DEĞİŞKENLERİNİ KORELASYONLARI YÜKSEK ÇIKTIĞINDAN GRUPLANDIRALIM**","metadata":{}},{"cell_type":"code","source":"# Korelasyonu yüksek olan değişkenleri gruplayalım\n\n# V16 ve V17'nin ortalamasını alalım\ndf['V16_V17_Group'] = (df['V16'] + df['V17']) / 2\n\n# V17 ve V18'in ortalamasını alalım\ndf['V17_V18_Group'] = (df['V17'] + df['V18']) / 2\n\n# İlk birkaç satırı kontrol edelim\nprint(df[['V16', 'V17', 'V18', 'V16_V17_Group', 'V17_V18_Group']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Diğer Değişkenlerin biribiri Arasında Korelasyonları","metadata":{}},{"cell_type":"code","source":"# İlgili değişkenler\nselected_columns = ['Amount', 'Class', 'V1_Amount_Interaction', 'Log_Amount',\n                    'V1_Amount_Interaction_Scaled', 'V1_V2_Interaction', 'V3_V4_Interaction',\n                    'Mean_V1_V2', 'Std_V1_V2', 'Var_V1_V2', 'V16_V17_Group', 'V17_V18_Group']\n\n# Korelasyon matrisini hesaplayalım\ncorrelation_matrix = df[selected_columns].corr()\n\n# Korelasyon matrisini görselleştirelim\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.2f')\nplt.title('Korelasyon Matrisi')\nplt.show()\n\n# Yüksek korelasyonları (0.8 ve üzeri) filtreleyelim\nhigh_correlation = correlation_matrix[correlation_matrix.abs() > 0.8]\n\n# Yüksek korelasyonları yazdıralım\nprint(high_correlation)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Yüksek korelasyona sahip olan sütunları silme\ndf = df.drop(columns=['V1_Amount_Interaction_Scaled', 'V16_V17_Group','V1_Squared', 'Log_Amount','V17_V18_Group','V17'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.heatmap(df.corr(), cmap='coolwarm')\nplt.title('Korelasyon Matrisi')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL SELECTİON(MODEL KURULUMU)","metadata":{}},{"cell_type":"code","source":"\n# Özellikleri ve hedefi ayırma\nX = df.drop(columns=['Class'],axis=1)\ny = df['Class']\n\n# Eğitim ve test setlerine ayırma\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model oluşturma\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\n# Tahmin ve değerlendirme\ny_pred = model.predict(X_test)\n\n# Model performansını yazdırma\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Modelinizi tanımlayın\nrf = RandomForestClassifier(random_state=42)\n\n# Çapraz doğrulama ile modelin doğruluğunu değerlendirin\ncv_scores = cross_val_score(rf, X, y, cv=3, scoring='accuracy')\n\n# Çapraz doğrulama sonuçları\nprint(f'Çapraz doğrulama ile doğruluk skorları: {cv_scores}')\nprint(f'Ortalama doğruluk: {np.mean(cv_scores)}')\nprint(f'Karmaşıklık: {np.std(cv_scores)}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_importance_ensemble(model, features, num=len(X)):\n    \n    feature_imp_df = pd.DataFrame(0, index=features.columns, columns=[\"Value\"])\n    \n    \n    for model in model.estimators_:\n        if hasattr(model, 'feature_importances_'):\n            \n            feature_imp_df[\"Value\"] += model.feature_importances_/100\n\n    \n    feature_imp_df[\"Feature\"] = features.columns\n    feature_imp_df = feature_imp_df.sort_values(by=\"Value\", ascending=False)\n    plt.figure(figsize=(12, 7))\n    sns.set(font_scale=1)\n    ax = sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp_df[0:num])\n    \n    for p in ax.patches:\n        ax.annotate(format(p.get_width(), '.4f'),\n                    (p.get_width(), p.get_y() + p.get_height() / 2),\n                    ha='left', va='center', fontsize=8)\n    \n    plt.title(\"Feature Importance -  Classifier\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_importance_ensemble(model,X)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Modelimizde en  çok tahmin skorunu etkileyen özellik V14 olmuştur bu sebeple V14  bizim için Frud tahmini sürecinde  kritik rol oynamaktadır bunun yanı sıra V12,V4,V11 özellikleri de farud izlenim sürecinde önemli bir özellik göstermektedir.**","metadata":{}}]}